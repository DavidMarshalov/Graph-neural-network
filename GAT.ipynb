{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "8HOfu-y2iWW1"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "#!pip install torch_geometric\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.datasets import Planetoid\n",
        "from torch_geometric.nn import GATConv\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ZSP2o0BjQP5"
      },
      "source": [
        "Cora - сеть научных статей по ml, где вершины — статьи, рёбра — ссылки (кто кого цитирует) у каждой вершины есть вектор признаков (bag-of-words по словам из текста статьи), а метка - научная категория статьи (класс).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QyXMZ7driWzU"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fV7t9kBJiW16",
        "outputId": "d7487ae1-06d4-4bce-a422-0702564b32aa"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.x\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.tx\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.allx\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.y\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.ty\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.ally\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.graph\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.test.index\n",
            "Processing...\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cora()\n",
            "Число вершин: 2708\n",
            "Число рёбер: 10556\n",
            "Число признаков: 1433\n",
            "Число классов: 7\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Done!\n"
          ]
        }
      ],
      "source": [
        "dataset = Planetoid(root='data/Cora', name='Cora')\n",
        "data = dataset[0].to(device)\n",
        "\n",
        "print(dataset)\n",
        "print(\"Число вершин:\", data.num_nodes)\n",
        "print(\"Число рёбер:\", data.num_edges)\n",
        "print(\"Число признаков:\", dataset.num_features)\n",
        "print(\"Число классов:\", dataset.num_classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I8KPh-oKiW4I"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AcGXZ63Uj6I4"
      },
      "source": [
        "Классификация вершин с помощью Graph Attention Network (GAT)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "ENFfB_MwiW6n"
      },
      "outputs": [],
      "source": [
        "class GAT(torch.nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        in_channels: int,\n",
        "        hidden_channels: int,\n",
        "        out_channels: int,\n",
        "        heads1: int = 8,\n",
        "        heads2: int = 1,\n",
        "        dropout: float = 0.6,\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.dropout = dropout\n",
        "\n",
        "        # первый слой: multi-head attention\n",
        "        self.conv1 = GATConv(\n",
        "            in_channels,\n",
        "            hidden_channels,\n",
        "            heads=heads1,\n",
        "            dropout=dropout,\n",
        "        )\n",
        "        # второй слой тоже GAT но без concat (выход сразу нужной размерности классов)\n",
        "        self.conv2 = GATConv(\n",
        "            hidden_channels * heads1,\n",
        "            out_channels,\n",
        "            heads=heads2,\n",
        "            concat=False,\n",
        "            dropout=dropout,\n",
        "        )\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        x = F.dropout(x, p=self.dropout, training=self.training)\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = F.elu(x)\n",
        "        x = F.dropout(x, p=self.dropout, training=self.training)\n",
        "        x = self.conv2(x, edge_index)\n",
        "        return x  # логиты классов\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "MWWUYzwriW8U"
      },
      "outputs": [],
      "source": [
        "\n",
        "def train_one_epoch(model, data, optimizer):\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "    out = model(data.x, data.edge_index)\n",
        "\n",
        "    # считаем loss только по train-вершинам\n",
        "    loss = F.cross_entropy(out[data.train_mask], data.y[data.train_mask])\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    return loss.item()\n",
        "\n",
        "@torch.no_grad()\n",
        "def eval_split(model, data, mask):\n",
        "    model.eval()\n",
        "    out = model(data.x, data.edge_index)\n",
        "    pred = out.argmax(dim=-1)\n",
        "    correct = (pred[mask] == data.y[mask]).sum().item()\n",
        "    total = int(mask.sum())\n",
        "    return correct / total\n",
        "\n",
        "@torch.no_grad()\n",
        "def eval_all(model, data):\n",
        "    return {\n",
        "        \"train_acc\": eval_split(model, data, data.train_mask),\n",
        "        \"val_acc\":   eval_split(model, data, data.val_mask),\n",
        "        \"test_acc\":  eval_split(model, data, data.test_mask),\n",
        "    }\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BvIuPiM6iW_a",
        "outputId": "1967cd72-813b-4622-9fb9-f0aa0bd2f728"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Обучаем модель с lr = 0.005 ===\n",
            "Epoch 001 | loss=1.9866 | train=0.521 | val=0.338 | test=0.359\n",
            "Epoch 020 | loss=0.9181 | train=0.986 | val=0.792 | test=0.802\n",
            "Epoch 040 | loss=0.6110 | train=0.993 | val=0.804 | test=0.812\n",
            "Epoch 060 | loss=0.4926 | train=0.993 | val=0.796 | test=0.812\n",
            "Epoch 080 | loss=0.5734 | train=1.000 | val=0.794 | test=0.803\n",
            "Epoch 100 | loss=0.4129 | train=1.000 | val=0.796 | test=0.801\n",
            "Epoch 120 | loss=0.5277 | train=1.000 | val=0.786 | test=0.798\n",
            "Epoch 140 | loss=0.4012 | train=1.000 | val=0.794 | test=0.810\n",
            "Epoch 160 | loss=0.3966 | train=1.000 | val=0.760 | test=0.786\n",
            "Epoch 180 | loss=0.3802 | train=1.000 | val=0.786 | test=0.805\n",
            "Epoch 200 | loss=0.4304 | train=1.000 | val=0.778 | test=0.798\n",
            "\n",
            "=== Обучаем модель с lr = 0.01 ===\n",
            "Epoch 001 | loss=2.0106 | train=0.579 | val=0.404 | test=0.398\n",
            "Epoch 020 | loss=0.7303 | train=0.979 | val=0.774 | test=0.785\n",
            "Epoch 040 | loss=0.5034 | train=1.000 | val=0.778 | test=0.797\n",
            "Epoch 060 | loss=0.3879 | train=1.000 | val=0.776 | test=0.796\n",
            "Epoch 080 | loss=0.4635 | train=1.000 | val=0.790 | test=0.807\n",
            "Epoch 100 | loss=0.3999 | train=1.000 | val=0.800 | test=0.802\n",
            "Epoch 120 | loss=0.4836 | train=1.000 | val=0.782 | test=0.807\n",
            "Epoch 140 | loss=0.3623 | train=1.000 | val=0.788 | test=0.793\n",
            "Epoch 160 | loss=0.4332 | train=1.000 | val=0.792 | test=0.799\n",
            "Epoch 180 | loss=0.3441 | train=1.000 | val=0.788 | test=0.794\n",
            "Epoch 200 | loss=0.4476 | train=1.000 | val=0.784 | test=0.803\n",
            "\n",
            "=== Обучаем модель с lr = 0.02 ===\n",
            "Epoch 001 | loss=2.0548 | train=0.779 | val=0.530 | test=0.541\n",
            "Epoch 020 | loss=0.7451 | train=0.993 | val=0.802 | test=0.817\n",
            "Epoch 040 | loss=0.5504 | train=0.993 | val=0.770 | test=0.791\n",
            "Epoch 060 | loss=0.4385 | train=1.000 | val=0.784 | test=0.815\n",
            "Epoch 080 | loss=0.3297 | train=1.000 | val=0.768 | test=0.781\n",
            "Epoch 100 | loss=0.3407 | train=1.000 | val=0.794 | test=0.798\n",
            "Epoch 120 | loss=0.3464 | train=1.000 | val=0.774 | test=0.798\n",
            "Epoch 140 | loss=0.4831 | train=0.993 | val=0.776 | test=0.789\n",
            "Epoch 160 | loss=0.3310 | train=1.000 | val=0.764 | test=0.776\n",
            "Epoch 180 | loss=0.4324 | train=1.000 | val=0.780 | test=0.797\n",
            "Epoch 200 | loss=0.5980 | train=1.000 | val=0.776 | test=0.793\n",
            "\n",
            "=== Лучший результат по валидации ===\n",
            "Лучший lr: 0.01\n",
            "Train acc: 1.000\n",
            "Val   acc: 0.784\n",
            "Test  acc: 0.803\n"
          ]
        }
      ],
      "source": [
        "#цикл по разным learning rate\n",
        "\n",
        "lrs = [0.005, 0.01, 0.02]  # можно поиграть\n",
        "num_epochs = 200\n",
        "\n",
        "best_val_acc = 0.0\n",
        "best_stats = None\n",
        "best_lr = None\n",
        "\n",
        "for lr in lrs:\n",
        "    print(f\"\\n=== Обучаем модель с lr = {lr} ===\")\n",
        "    model = GAT(\n",
        "        in_channels=dataset.num_features,\n",
        "        hidden_channels=8,\n",
        "        out_channels=dataset.num_classes,\n",
        "        heads1=8,\n",
        "        heads2=1,\n",
        "        dropout=0.6,\n",
        "    ).to(device)\n",
        "\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=5e-4)\n",
        "\n",
        "    for epoch in range(1, num_epochs + 1):\n",
        "        loss = train_one_epoch(model, data, optimizer)\n",
        "\n",
        "        if epoch % 20 == 0 or epoch == 1:\n",
        "            stats = eval_all(model, data)\n",
        "            print(\n",
        "                f\"Epoch {epoch:03d} | loss={loss:.4f} | \"\n",
        "                f\"train={stats['train_acc']:.3f} | \"\n",
        "                f\"val={stats['val_acc']:.3f} | \"\n",
        "                f\"test={stats['test_acc']:.3f}\"\n",
        "            )\n",
        "\n",
        "    # финальная оценка для этого lr\n",
        "    stats = eval_all(model, data)\n",
        "    if stats[\"val_acc\"] > best_val_acc:\n",
        "        best_val_acc = stats[\"val_acc\"]\n",
        "        best_stats = stats\n",
        "        best_lr = lr\n",
        "\n",
        "print(\"\\n=== Лучший результат по валидации ===\")\n",
        "print(f\"Лучший lr: {best_lr}\")\n",
        "print(f\"Train acc: {best_stats['train_acc']:.3f}\")\n",
        "print(f\"Val   acc: {best_stats['val_acc']:.3f}\")\n",
        "print(f\"Test  acc: {best_stats['test_acc']:.3f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rWhi0U0cjwWN"
      },
      "source": [
        "GAT с lr =  0.01 обучилась хорошо, на трейне она почти идеально подогналась под данные,\n",
        "а качество на валидации и тесте около 78–80%, что показывает хорошую обобщающую способность без сильного переобучения"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j51ue1f5iXBv"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l3dhsnYuiXD_"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MS2vgu1VlIsS"
      },
      "source": [
        "Задача 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "zuzAjCe4lwrk"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from torch_geometric.datasets import RelLinkPredDataset\n",
        "from torch_geometric.transforms import RandomLinkSplit\n",
        "\n",
        "from torch_geometric.utils import subgraph\n",
        "from torch_geometric.data import Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iJ71JUAhlKir"
      },
      "source": [
        "FB15k-237- граф знаний, где вершины — сущности (люди, фильмы, компании и тд), а рёбра — типизированные отношения между ними (всего 237 разных типов отношений)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RiDnaK3HiXGF",
        "outputId": "2b5058ad-4595-4039-a76f-71a2c9c648b6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data(edge_index=[2, 544230], num_nodes=14541, edge_type=[544230], train_edge_index=[2, 272115], train_edge_type=[272115], valid_edge_index=[2, 17535], valid_edge_type=[17535], test_edge_index=[2, 20466], test_edge_type=[20466])\n",
            "Число вершин (entities): 14541\n",
            "Число рёбер (трёхк): 544230\n",
            "Пример edge_type shape: torch.Size([544230])\n",
            "Максимальный тип ребра: 473  всего отношений: 474\n"
          ]
        }
      ],
      "source": [
        "dataset = RelLinkPredDataset(root='data/FB15k237', name='FB15k-237')\n",
        "data = dataset[0]\n",
        "\n",
        "print(data)\n",
        "print(\"Число вершин (entities):\", data.num_nodes)\n",
        "print(\"Число рёбер (трёхк):\", data.edge_index.shape[1])\n",
        "print(\"Пример edge_type shape:\", data.edge_type.shape)\n",
        "print(\"Максимальный тип ребра:\", int(data.edge_type.max()), \" всего отношений:\",\n",
        "      int(data.edge_type.max()) + 1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "# для быстро сокращу немного датасет\n",
        "max_edges = 40000\n",
        "\n",
        "num_edges = data.edge_index.size(1)\n",
        "perm = torch.randperm(num_edges)[:max_edges]\n",
        "\n",
        "edge_index = data.edge_index[:, perm]\n",
        "edge_type = data.edge_type[perm]\n",
        "\n",
        "nodes = torch.unique(edge_index)\n",
        "edge_index, edge_type = subgraph(\n",
        "    nodes,\n",
        "    edge_index,\n",
        "    edge_attr=edge_type,  \n",
        "    relabel_nodes=True,\n",
        ")\n",
        "\n",
        "data = Data(\n",
        "    edge_index=edge_index,\n",
        "    edge_type=edge_type,\n",
        "    num_nodes=int(edge_index.max()) + 1,\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aCzLMPWtiXIK",
        "outputId": "61873256-f46c-48d6-9eb7-8b3eaaef56de"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data(edge_index=[2, 32000], edge_type=[32000], num_nodes=12419, edge_label=[64000], edge_label_index=[2, 64000])\n",
            "train edge_label_index shape: torch.Size([2, 64000])\n",
            "train edge_label shape: torch.Size([64000])\n"
          ]
        }
      ],
      "source": [
        "# разбиение рёбер для задачи link prediction\n",
        "\n",
        "\n",
        "transform = RandomLinkSplit(\n",
        "    num_val=0.1,          #\n",
        "    num_test=0.1,\n",
        "    is_undirected=False,\n",
        "    add_negative_train_samples=True,  # для генерации негативных примеров\n",
        "    neg_sampling_ratio=1.0            # 1 отрицательное ребро на 1 положительное\n",
        ")\n",
        "\n",
        "train_data, val_data, test_data = transform(data)\n",
        "\n",
        "train_data = train_data.to(device)\n",
        "val_data   = val_data.to(device)\n",
        "test_data  = test_data.to(device)\n",
        "\n",
        "print(train_data)\n",
        "print(\"train edge_label_index shape:\", train_data.edge_label_index.shape)\n",
        "print(\"train edge_label shape:\", train_data.edge_label.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PsCBi266iXKP"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "Gcn38striXMV"
      },
      "outputs": [],
      "source": [
        "from torch_geometric.nn import RGATConv\n",
        "\n",
        "class RGATEncoder(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        num_nodes: int,\n",
        "        num_relations: int,\n",
        "        emb_dim: int = 64,\n",
        "        hidden_dim: int = 64,\n",
        "        out_dim: int = 64,\n",
        "        num_heads: int = 2,\n",
        "        dropout: float = 0.3,\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.dropout = dropout\n",
        "\n",
        "        # лбучаемые эмбеддинги вершин\n",
        "        self.node_emb = nn.Embedding(num_nodes, emb_dim)\n",
        "\n",
        "        # attention по рёбрам с учётом типа связи\n",
        "        self.conv1 = RGATConv(\n",
        "            in_channels=emb_dim,\n",
        "            out_channels=hidden_dim,\n",
        "            num_relations=num_relations,\n",
        "            heads=num_heads,\n",
        "            dropout=dropout,\n",
        "            concat=True,\n",
        "        )\n",
        "\n",
        "        self.conv2 = RGATConv(\n",
        "            in_channels=hidden_dim * num_heads,\n",
        "            out_channels=out_dim,\n",
        "            num_relations=num_relations,\n",
        "            heads=num_heads,\n",
        "            dropout=dropout,\n",
        "            concat=False,   # усредняются головы и получаем размер out_dim\n",
        "        )\n",
        "\n",
        "    def forward(self, edge_index, edge_type):\n",
        "        x = self.node_emb.weight\n",
        "\n",
        "        x = F.dropout(x, p=self.dropout, training=self.training)\n",
        "        x = self.conv1(x, edge_index, edge_type)\n",
        "        x = F.relu(x)\n",
        "\n",
        "        x = F.dropout(x, p=self.dropout, training=self.training)\n",
        "        x = self.conv2(x, edge_index, edge_type)\n",
        "\n",
        "        return x  # размер [num_nodes, out_dim]\n",
        "\n",
        "class LinkPredictor(nn.Module):\n",
        "    def __init__(self, in_dim: int, hidden_dim: int = 64):\n",
        "        super().__init__()\n",
        "        self.mlp = nn.Sequential(\n",
        "            nn.Linear(2 * in_dim, hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_dim, 1),\n",
        "        )\n",
        "\n",
        "    def forward(self, x_i, x_j):\n",
        "        # конкатенация эмбеддингов  + mlp\n",
        "        h = torch.cat([x_i, x_j], dim=-1)\n",
        "        out = self.mlp(h).squeeze(-1)  # логиты\n",
        "        return out\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "POeOeUv5iXOP"
      },
      "outputs": [],
      "source": [
        "\n",
        "def get_edge_embeddings(emb, edge_label_index):\n",
        "    src, dst = edge_label_index\n",
        "    return emb[src], emb[dst]\n",
        "\n",
        "\n",
        "def train_one_epoch(encoder, predictor, data, optimizer):\n",
        "    encoder.train()\n",
        "    predictor.train()\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # эмбеддинги всех узлов\n",
        "    node_emb = encoder(data.edge_index, data.edge_type)\n",
        "    ei, ej = get_edge_embeddings(node_emb, data.edge_label_index)\n",
        "    logits = predictor(ei, ej)\n",
        "    labels = data.edge_label.float()\n",
        "\n",
        "    loss = F.binary_cross_entropy_with_logits(logits, labels)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    return loss.item()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "ldjGbkswiXQf"
      },
      "outputs": [],
      "source": [
        "@torch.no_grad()\n",
        "def eval_split(encoder, predictor, data):\n",
        "    encoder.eval()\n",
        "    predictor.eval()\n",
        "\n",
        "    node_emb = encoder(data.edge_index, data.edge_type)\n",
        "    ei, ej = get_edge_embeddings(node_emb, data.edge_label_index)\n",
        "    logits = predictor(ei, ej)\n",
        "    probs = torch.sigmoid(logits)\n",
        "\n",
        "    labels = data.edge_label.float()\n",
        "\n",
        "    pred_labels = (probs > 0.5).float()\n",
        "    acc = (pred_labels == labels).float().mean().item()\n",
        "\n",
        "    return acc\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r4V9OXq1iXSk",
        "outputId": "c6e877d5-02ed-483d-90dc-ec1db92907f4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Обучаем RGAT-модель для link prediction, lr = 0.001 ===\n",
            "Epoch 001 | loss=0.6937 | train_acc=0.506 | val_acc=0.508 | test_acc=0.502\n",
            "Epoch 010 | loss=0.6155 | train_acc=0.709 | val_acc=0.700 | test_acc=0.686\n",
            "Epoch 020 | loss=0.5578 | train_acc=0.754 | val_acc=0.738 | test_acc=0.733\n",
            "\n",
            "=== Обучаем RGAT-модель для link prediction, lr = 0.0005 ===\n",
            "Epoch 001 | loss=0.6971 | train_acc=0.501 | val_acc=0.500 | test_acc=0.501\n",
            "Epoch 010 | loss=0.6769 | train_acc=0.544 | val_acc=0.535 | test_acc=0.534\n",
            "Epoch 020 | loss=0.6289 | train_acc=0.673 | val_acc=0.661 | test_acc=0.659\n",
            "\n",
            "=== Лучший результат по валидации для RGATLinkPrediction ===\n",
            "Лучший lr: 0.001\n",
            "Val   acc: 0.738\n",
            "Test  acc: 0.733\n"
          ]
        }
      ],
      "source": [
        "num_nodes = data.num_nodes\n",
        "num_relations = int(data.edge_type.max().item()) + 1\n",
        "\n",
        "lrs = [1e-3, 5e-4]\n",
        "num_epochs = 20\n",
        "\n",
        "best_val_acc = 0.0\n",
        "best_test_acc = 0.0\n",
        "best_lr = None\n",
        "\n",
        "for lr in lrs:\n",
        "    print(f\"\\n=== Обучаем RGAT-модель для link prediction, lr = {lr} ===\")\n",
        "\n",
        "    encoder = RGATEncoder(\n",
        "        num_nodes=num_nodes,\n",
        "        num_relations=num_relations,\n",
        "        emb_dim=64,\n",
        "        hidden_dim=64,\n",
        "        out_dim=64,\n",
        "        num_heads=2,\n",
        "        dropout=0.3,\n",
        "    ).to(device)\n",
        "\n",
        "    predictor = LinkPredictor(in_dim=64, hidden_dim=64).to(device)\n",
        "\n",
        "    optimizer = torch.optim.Adam(\n",
        "        list(encoder.parameters()) + list(predictor.parameters()),\n",
        "        lr=lr,\n",
        "        weight_decay=1e-5,\n",
        "    )\n",
        "\n",
        "    for epoch in range(1, num_epochs + 1):\n",
        "        loss = train_one_epoch(encoder, predictor, train_data, optimizer)\n",
        "\n",
        "        if epoch % 10 == 0 or epoch == 1:\n",
        "            train_acc = eval_split(encoder, predictor, train_data)\n",
        "            val_acc = eval_split(encoder, predictor, val_data)\n",
        "            test_acc = eval_split(encoder, predictor, test_data)\n",
        "\n",
        "            print(\n",
        "                f\"Epoch {epoch:03d} | loss={loss:.4f} | \"\n",
        "                f\"train_acc={train_acc:.3f} | val_acc={val_acc:.3f} | test_acc={test_acc:.3f}\"\n",
        "            )\n",
        "\n",
        "    val_acc = eval_split(encoder, predictor, val_data)\n",
        "    test_acc = eval_split(encoder, predictor, test_data)\n",
        "\n",
        "    if val_acc > best_val_acc:\n",
        "        best_val_acc = val_acc\n",
        "        best_test_acc = test_acc\n",
        "        best_lr = lr\n",
        "\n",
        "print(\"\\n=== Лучший результат по валидации для RGATLinkPrediction ===\")\n",
        "print(f\"Лучший lr: {best_lr}\")\n",
        "print(f\"Val   acc: {best_val_acc:.3f}\")\n",
        "print(f\"Test  acc: {best_test_acc:.3f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "RGAT-модель хорошо выучила структуру гетерогенного графа, качество на валидации и тесте около 0.73, без сильного переобучения"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7JCm_DlViXiN"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rrsLKhsSiXkj"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
